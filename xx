[1mdiff --git a/train/export_onnx.py b/train/export_onnx.py[m
[1mindex 189144c..38b1423 100644[m
[1m--- a/train/export_onnx.py[m
[1m+++ b/train/export_onnx.py[m
[36m@@ -76,9 +76,10 @@[m [mclass ONNXExportWrapper(torch.nn.Module):[m
         return pruned_outputs[m
 [m
 [m
[31m-def export_to_onnx(model: Model, export_path: str, pos_len: int = 19, [m
[32m+[m[32mdef export_to_onnx(model: Model, save_name: str ,export_path: str, pos_len: int = 19,[m[41m [m
                    batch_size: int = 1, opset_version: int = 20, disable_mask: bool = False,[m
[31m-                   verbose: bool = False) -> None:[m
[32m+[m[32m                   verbose: bool = False, extra_meta_data: Dict[str, str] = None,[m
[32m+[m[32m                   auto_fp16: bool = False) -> None:[m
     """[m
     Export PyTorch model to ONNX format.[m
     [m
[36m@@ -89,6 +90,7 @@[m [mdef export_to_onnx(model: Model, export_path: str, pos_len: int = 19,[m
         batch_size: Batch size for the model[m
         opset_version: ONNX opset version[m
         verbose: Whether to enable verbose logging[m
[32m+[m[32m        auto_fp16: Whether to automatically convert to mixed precision (FP16)[m
     """[m
     [m
     # Set model to evaluation mode[m
[36m@@ -99,9 +101,11 @@[m [mdef export_to_onnx(model: Model, export_path: str, pos_len: int = 19,[m
     wrapper.eval()[m
     [m
     # Create dummy inputs[m
[31m-    input_spatial = torch.randn(batch_size, 22, pos_len, pos_len, dtype=torch.float32)[m
[32m+[m[32m    num_spatial_inputs = modelconfigs.get_num_bin_input_features(model.config)[m
[32m+[m[32m    input_spatial = torch.randn(batch_size, num_spatial_inputs, pos_len, pos_len, dtype=torch.float32)[m
     input_spatial[:,0,:,:]=1.0[m
[31m-    input_global = torch.randn(batch_size, 19, dtype=torch.float32)[m
[32m+[m[32m    num_global_inputs = modelconfigs.get_num_global_input_features(model.config)[m
[32m+[m[32m    input_global = torch.randn(batch_size, num_global_inputs, dtype=torch.float32)[m
     [m
     # Prepare inputs and input names[m
     inputs = [input_spatial, input_global][m
[36m@@ -160,6 +164,69 @@[m [mdef export_to_onnx(model: Model, export_path: str, pos_len: int = 19,[m
     [m
     logging.info("ONNX export completed successfully!")[m
 [m
[32m+[m[32m    # Auto convert to FP16 if requested[m
[32m+[m[32m    if auto_fp16:[m
[32m+[m[32m        assert False,"Currently has trouble converting RMSNorm to fp16. Do not use -auto-fp16"[m
[32m+[m[41m        [m
[32m+[m[32m        import onnx[m
[32m+[m[32m        from onnxconverter_common import auto_convert_mixed_precision,float16[m
[32m+[m
[32m+[m[32m        logging.info("Converting model to auto mixed precision (FP16)...")[m
[32m+[m[41m        [m
[32m+[m[32m        onnx_model = onnx.load(export_path)[m
[32m+[m[32m        # Create feed_dict with dummy inputs converted to numpy[m
[32m+[m[32m        feed_dict = {name: tensor.detach().cpu().numpy() for name, tensor in zip(input_names, inputs)}[m
[32m+[m[32m        onnx_model_fp16 = auto_convert_mixed_precision(onnx_model, feed_dict, rtol=0.01, keep_io_types=True)[m
[32m+[m[32m        #onnx_model_fp16 = float16.convert_float_to_float16(onnx_model)[m
[32m+[m[32m        onnx.save(onnx_model_fp16, export_path)[m
[32m+[m[32m        logging.info("Converted to FP16 successfully.")[m
[32m+[m[41m            [m
[32m+[m
[32m+[m[32m    # Add metadata to the ONNX model[m
[32m+[m[32m    try:[m
[32m+[m[32m        import onnx[m
[32m+[m[32m        from onnx import helper[m
[32m+[m[41m        [m
[32m+[m[32m        onnx_model = onnx.load(export_path)[m
[32m+[m[41m        [m
[32m+[m[32m        # Add metadata_props[m
[32m+[m[32m        meta = {[m
[32m+[m[32m            "name": save_name,[m
[32m+[m[32m            "modelVersion": str(model.config["version"]),[m
[32m+[m[32m            # Add other useful info if available[m
[32m+[m[32m            "exported_at": datetime.datetime.now().isoformat(),[m
[32m+[m[32m            "auto_fp16_already": "true" if auto_fp16 else "false",[m
[32m+[m[32m            "opset_version": str(opset_version),[m
[32m+[m[32m            "exported_with_dynamo": "true" if dynamo else "false",[m
[32m+[m[32m            "num_spatial_inputs": str(num_spatial_inputs),[m
[32m+[m[32m            "num_global_inputs": str(num_global_inputs),[m
[32m+[m[32m            "pos_len": str(pos_len),[m
[32m+[m[32m            "pos_len_x": str(pos_len),[m
[32m+[m[32m            "pos_len_y": str(pos_len),[m
[32m+[m[32m            "has_mask": "true" if not disable_mask else "false",[m
[32m+[m[32m            "model_config": str(model.config)[m
[32m+[m[32m        }[m
[32m+[m[32m        if extra_meta_data is not None:[m
[32m+[m[32m            meta.update(extra_meta_data)[m
[32m+[m[41m        [m
[32m+[m[32m        # Clear existing metadata if any to avoid duplicates[m
[32m+[m[32m        if hasattr(onnx_model, "metadata_props"):[m
[32m+[m[32m            del onnx_model.metadata_props[:][m
[32m+[m[41m            [m
[32m+[m[32m        for key, value in meta.items():[m
[32m+[m[32m            meta_entry = onnx_model.metadata_props.add()[m
[32m+[m[32m            meta_entry.key = key[m
[32m+[m[32m            meta_entry.value = value[m
[32m+[m[41m            [m
[32m+[m[32m        # Save the model with metadata[m
[32m+[m[32m        onnx.save(onnx_model, export_path)[m
[32m+[m[32m        logging.info(f"Added metadata to ONNX model: {meta}")[m
[32m+[m[41m        [m
[32m+[m[32m    except ImportError:[m
[32m+[m[32m        logging.warning("onnx package not installed, skipping metadata addition")[m
[32m+[m[32m    except Exception as e:[m
[32m+[m[32m        logging.error(f"Failed to add metadata: {e}")[m
[32m+[m
 [m
 def verify_onnx_model(onnx_path: str, original_model: Model, pos_len: int = 19, [m
                       batch_size: int = 1, ignore_intermediate_head: bool = True) -> bool:[m
[36m@@ -187,9 +254,11 @@[m [mdef verify_onnx_model(onnx_path: str, original_model: Model, pos_len: int = 19,[m
     ort_session = ort.InferenceSession(onnx_path)[m
     [m
     # Create test inputs[m
[31m-    input_spatial = torch.randn(batch_size, 22, pos_len, pos_len, dtype=torch.float32)[m
[32m+[m[32m    num_spatial_inputs = modelconfigs.get_num_bin_input_features(model.config)[m
[32m+[m[32m    input_spatial = torch.randn(batch_size, num_spatial_inputs, pos_len, pos_len, dtype=torch.float32)[m
     input_spatial[:,0,:,:]=1.0[m
[31m-    input_global = torch.randn(batch_size, 19, dtype=torch.float32)[m
[32m+[m[32m    num_global_inputs = modelconfigs.get_num_global_input_features(model.config)[m
[32m+[m[32m    input_global = torch.randn(batch_size, num_global_inputs, dtype=torch.float32)[m
     [m
     # Get PyTorch outputs[m
     original_model.eval()[m
[36m@@ -245,11 +314,14 @@[m [mif __name__ == "__main__":[m
         parser.add_argument('-model-name', help='Name for the exported model', required=True)[m
         parser.add_argument('-use-swa', help='Use SWA model if available', action='store_true', required=False)[m
         parser.add_argument('-pos-len', help='Spatial edge length (e.g. 19 for 19x19 Go)', type=int, default=19, required=False)[m
[31m-        parser.add_argument('-batch-size', help='Batch size for ONNX export', type=int, default=1, required=False)[m
[32m+[m[32m        parser.add_argument('-batch-size', help='Batch size for ONNX export', type=int, default=4, required=False)[m
         parser.add_argument('-opset-version', help='ONNX opset version', type=int, default=20, required=False)[m
         parser.add_argument('-simplify', help='Simplify ONNX model using onnx-simplifier', action='store_true', required=False)[m
         parser.add_argument('-disable-mask', help='Disable masks in CNN and attention', action='store_true', required=False)[m
[32m+[m[32m        parser.add_argument('-auto-fp16', help='Convert to half precision (FP16) automatically', action='store_true', required=False)[m
         parser.add_argument('-verbose', help='Verbose output', action='store_true', required=False)[m
[32m+[m[32m        parser.add_argument('-author', help='Author name for metadata', required=False,default="unknown")[m
[32m+[m[32m        parser.add_argument('-comment', help='Comment for metadata', required=False,default="")[m
         [m
         args = parser.parse_args()[m
 [m
[36m@@ -264,7 +336,15 @@[m [mif __name__ == "__main__":[m
         opset_version = args.opset_version[m
         simplify = args.simplify[m
         disable_mask = args.disable_mask[m
[32m+[m[32m        auto_fp16 = args.auto_fp16[m
         verbose = args.verbose[m
[32m+[m[32m        author = args.author[m
[32m+[m[32m        comment = args.comment[m
[32m+[m[32m        extra_meta_data = {}[m
[32m+[m[32m        if author is not None:[m
[32m+[m[32m            extra_meta_data["author"] = author[m
[32m+[m[32m        if comment is not None:[m
[32m+[m[32m            extra_meta_data["comment"] = comment[m
     else:[m
         checkpoint_file = "../data/train/go_b24c128tf1b_muon1_fd1/checkpoint.ckpt"[m
         export_dir = "../onnx_exports"[m
[36m@@ -274,6 +354,7 @@[m [mif __name__ == "__main__":[m
         batch_size = 128[m
         opset_version = 20[m
         simplify = False[m
[32m+[m[32m        auto_fp16 = False[m
         verbose = False[m
     [m
     # Create export directory[m
[36m@@ -307,17 +388,28 @@[m [mif __name__ == "__main__":[m
     logging.info(f"Model config: {export_model.config}")[m
     [m
     # Export to ONNX[m
[31m-    onnx_filename = f"{model_name}.onnx"[m
[32m+[m[32m    save_name = f"{model_name}"[m
[32m+[m[32m    # Add training state info if available[m
[32m+[m[32m    if "train_state" in other_state_dict:[m
[32m+[m[32m        train_state = other_state_dict["train_state"][m
[32m+[m[32m        if "global_step_samples" in train_state:[m
[32m+[m[32m            save_name += f"-s{train_state['global_step_samples']}"[m
[32m+[m[32m        if "total_num_data_rows" in train_state:[m
[32m+[m[32m            save_name += f"-d{train_state['total_num_data_rows']}"[m
[32m+[m[32m    onnx_filename = f"{save_name}.onnx"[m
     onnx_path = os.path.join(export_dir, onnx_filename)[m
     [m
     export_to_onnx([m
         export_model, [m
[32m+[m[32m        save_name,[m
         onnx_path, [m
         pos_len=pos_len, [m
         batch_size=batch_size, [m
         opset_version=opset_version,[m
         disable_mask=disable_mask,[m
[31m-        verbose=verbose[m
[32m+[m[32m        verbose=verbose,[m
[32m+[m[32m        extra_meta_data=extra_meta_data,[m
[32m+[m[32m        auto_fp16=auto_fp16[m
     )[m
     [m
     # Verify the exported model[m
[1mdiff --git a/train/metrics_pytorch.py b/train/metrics_pytorch.py[m
[1mindex 331ec17..f87bb2b 100644[m
[1m--- a/train/metrics_pytorch.py[m
[1m+++ b/train/metrics_pytorch.py[m
[36m@@ -613,7 +613,7 @@[m [mclass Metrics:[m
         assert target_weight_longoptimistic_policy.shape[0] == n[m
         target_weight_longoptimistic_policy_sum = (global_weight * target_weight_longoptimistic_policy).sum()[m
 [m
[31m-        if raw_model.config["version"] <= 11 or (raw_model.config["version"] >= 101 and raw_model.config["version"] <= 199)::[m
[32m+[m[32m        if raw_model.config["version"] <= 11 or (raw_model.config["version"] >= 101 and raw_model.config["version"] <= 199):[m
             target_weight_shortoptimistic_policy = torch.zeros_like(global_weight)[m
             loss_shortoptimistic_policy = torch.zeros_like(loss_policy_player)[m
         elif disable_optimistic_policy:[m
[1mdiff --git a/train/modelconfigs.py b/train/modelconfigs.py[m
[1mindex c32fccd..3b86327 100644[m
[1m--- a/train/modelconfigs.py[m
[1m+++ b/train/modelconfigs.py[m
[36m@@ -1378,6 +1378,48 @@[m [mb46c192h6tfrs = {[m
     "v2_size":128,[m
 }[m
 [m
[32m+[m[32mb18c384h12tfrs = {[m
[32m+[m[32m    "version":15,[m
[32m+[m[32m    "norm_kind":"fixup",[m
[32m+[m[32m    "bnorm_epsilon": 1e-4,[m
[32m+[m[32m    "bnorm_running_avg_momentum": 0.001,[m
[32m+[m[32m    "initial_conv_1x1": False,[m
[32m+[m[32m    "trunk_num_channels":384,[m
[32m+[m[32m    "mid_num_channels":384,[m
[32m+[m[32m    "gpool_num_channels":64,[m
[32m+[m[32m    "transformer_ffn_channels":1024,[m
[32m+[m[32m    "transformer_heads":12,[m
[32m+[m[32m    "transformer_kv_heads":12,[m
[32m+[m[32m    "use_attention_pool":False,[m
[32m+[m[32m    "num_attention_pool_heads":4,[m
[32m+[m[32m    "block_kind": [[m
[32m+[m[32m        ["rconv1","transformerropesg"],[m
[32m+[m[32m        ["rconv2","transformerropesg"],[m
[32m+[m[32m        ["rconv3","transformerropesg"],[m
[32m+[m[32m        ["rconv4","transformerropesg"],[m
[32m+[m[32m        ["rconv5","transformerropesg"],[m
[32m+[m[32m        ["rconv6","transformerropesg"],[m
[32m+[m[32m        ["rconv7","transformerropesg"],[m
[32m+[m[32m        ["rconv8","transformerropesg"],[m
[32m+[m[32m        ["rconv9","transformerropesg"],[m
[32m+[m[32m        ["rconv10","transformerropesg"],[m
[32m+[m[32m        ["rconv11","transformerropesg"],[m
[32m+[m[32m        ["rconv12","transformerropesg"],[m
[32m+[m[32m        ["rconv13","transformerropesg"],[m
[32m+[m[32m        ["rconv14","transformerropesg"],[m
[32m+[m[32m        ["rconv15","transformerropesg"],[m
[32m+[m[32m        ["rconv16","transformerropesg"],[m
[32m+[m[32m        ["rconv17","transformerropesg"],[m
[32m+[m[32m        ["rconv18","transformerropesg"],[m
[32m+[m[32m    ],[m
[32m+[m[32m    "p1_num_channels":48,[m
[32m+[m[32m    "g1_num_channels":48,[m
[32m+[m[32m    "v1_num_channels":96,[m
[32m+[m[32m    "sbv2_num_channels":128,[m
[32m+[m[32m    "num_scorebeliefs":8,[m
[32m+[m[32m    "v2_size":128,[m
[32m+[m[32m}[m
[32m+[m
 b10c768h24tfrs = {[m
     "version":15,[m
     "norm_kind":"fixup",[m
[36m@@ -1795,6 +1837,9 @@[m [mbase_config_of_name = {[m
     "b24c256h8tfrs":b24c256h8tfrs, [m
     "b46c192h6tfrs":b46c192h6tfrs, [m
 [m
[32m+[m[32m# 32M parameter[m
[32m+[m[32m    "b18c384h12tfrs":b18c384h12tfrs,[m[41m [m
[32m+[m
 # 70M parameter:[m
     "b10c768h24tfrs":b10c768h24tfrs, [m
     "b21c512h16tfrs":b21c512h16tfrs, [m
[1mdiff --git a/train/train_muon_ki.py b/train/train_muon_ki.py[m
[1mindex bdfc2f5..e6ce8ab 100644[m
[1m--- a/train/train_muon_ki.py[m
[1m+++ b/train/train_muon_ki.py[m
[36m@@ -357,18 +357,18 @@[m [mdef main(rank: int, world_size: int, args, multi_gpu_device_ids, readpipes, writ[m
             return lr0 * 2 ** (-1.5)[m
         if t < 2.0**4:[m
             return lr0 * 2 ** (-2.0)[m
[31m-        if t < 2.0**5:[m
[32m+[m[32m        if t < 24:[m
             return lr0 * 2 ** (-2.5)[m
         # final drop[m
[31m-        if t < 36:[m
[32m+[m[32m        if t < 25:[m
             return lr0 * 2 ** (-3.0)[m
[31m-        if t < 40:[m
[32m+[m[32m        if t < 26:[m
             return lr0 * 2 ** (-3.5)[m
[31m-        if t < 42:[m
[32m+[m[32m        if t < 28:[m
             return lr0 * 2 ** (-4.0)[m
[31m-        if t < 44:[m
[32m+[m[32m        if t < 30:[m
             return lr0 * 2 ** (-5.0)[m
[31m-        if t < 45:[m
[32m+[m[32m        if t < 32:[m
             return lr0 * 2 ** (-6.0)[m
         return lr0 * 2 ** (-7.0)[m
     [m
[1mdiff --git a/train/view_loss.py b/train/view_loss.py[m
[1mindex a59ed65..44c65f9 100644[m
[1m--- a/train/view_loss.py[m
[1m+++ b/train/view_loss.py[m
[36m@@ -1,8 +1,8 @@[m
 baseDir="../data/train/"[m
[31m-lossItems={"p0loss":(1.7,2.5),"vloss":(0.6,0.7),"loss":(50.5,52),"pacc1":(0.35,0.45),"gnorm_batch":(0,40000),"exgnorm":(0,0),"norm_normal_batch":(0,0),"norm_normal_attn_batch":(0,0),"norm_output_batch":(0,0),"norm_noreg_batch":(0,0),"norm_output_noreg_batch":(0,0),"pslr_batch":(1e-7,1e-2)}#name,ylim,  0 means default[m
[32m+[m[32mlossItems={"p0loss":(1.7,2.2),"vloss":(0.6,0.7),"loss":(50.5,52),"pacc1":(0.40,0.5),"gnorm_batch":(0,40000),"exgnorm":(0,0),"norm_normal_batch":(0,0),"norm_normal_attn_batch":(0,0),"norm_output_batch":(0,0),"norm_noreg_batch":(0,0),"norm_output_noreg_batch":(0,0),"pslr_batch":(1e-7,1e-2)}#name,ylim,  0 means default[m
 [m
 [m
[31m-trainDirs=["ref_b30c128h4tfrs","b14c192h6tfrs_1","b14c192h6tfrs_1_old"][m
[32m+[m[32mtrainDirs=["ref_b30c128h4tfrs","b14c192h6tfrs_1_old","b14c192h6tfrs_1_fd1","b14c192h6tfrs_1_fd2","b14c192h6tfrs_1",][m
 [m
 autoBias=False[m
 biases=None[m
[36m@@ -16,7 +16,7 @@[m [mlossTypes=["train","val_swa0"][m
 outputFile="../losstf.png"[m
 [m
 logPlot=True[m
[31m-logPlotXmin=1e6[m
[32m+[m[32mlogPlotXmin=1e8[m
 logPlotXmax=1e10[m
 #logPlotXmax=None[m
 #smooth_window=100[m
